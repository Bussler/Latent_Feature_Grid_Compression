{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3f748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bussler/anaconda3/envs/DeepLearning/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[INFO 01-27 20:08:24] ax.modelbridge.dispatch_utils: Using Bayesian optimization since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
      "[INFO 01-27 20:08:24] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+MOO', steps=[Sobol for 12 trials, MOO for subsequent trials]). Iterations after 12 will take longer to generate due to  model-fitting.\n",
      "[INFO 01-27 20:08:24] Scheduler: `Scheduler` requires experiment to have immutable search space and optimization config. Setting property immutable_search_space_and_opt_config to `True` on experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG_DIR:  NAS_Experiments/MHD_P_Baseline/\n"
     ]
    }
   ],
   "source": [
    "from Multi_Objective_NAS import create_experiment_scheduler, create_experiment_scheduler_baseline\n",
    "\n",
    "config = 'experiment-config-files/mhd_p_HyperparamSearch.txt'\n",
    "\n",
    "experiment, scheduler = create_experiment_scheduler_baseline(config, 'Feature_Grid_Training.py', 'mhd_p_', 'NAS_Experiments/MHD_P_Baseline/', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e183a7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bussler/anaconda3/envs/DeepLearning/lib/python3.10/site-packages/ax/core/observation.py:274: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for g, d in df.groupby(by=cols):\n",
      "[INFO 01-27 20:08:27] Scheduler: Running trials [0]...\n",
      "/home/bussler/anaconda3/envs/DeepLearning/lib/python3.10/site-packages/ax/core/observation.py:274: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for g, d in df.groupby(by=cols):\n",
      "[INFO 01-27 20:08:28] Scheduler: Running trials [1]...\n",
      "/home/bussler/anaconda3/envs/DeepLearning/lib/python3.10/site-packages/ax/core/observation.py:274: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for g, d in df.groupby(by=cols):\n",
      "[INFO 01-27 20:08:29] Scheduler: Running trials [2]...\n",
      "[INFO 01-27 20:08:30] Scheduler: Waiting for completed trials (for 1 sec, currently running trials: 3).\n",
      "[INFO 01-27 20:08:31] Scheduler: Waiting for completed trials (for 1.5 sec, currently running trials: 3).\n",
      "[INFO 01-27 20:08:32] Scheduler: Waiting for completed trials (for 2 sec, currently running trials: 3).\n",
      "[INFO 01-27 20:08:35] Scheduler: Waiting for completed trials (for 3 sec, currently running trials: 3).\n",
      "[INFO 01-27 20:08:38] Scheduler: Waiting for completed trials (for 5 sec, currently running trials: 3).\n"
     ]
    },
    {
     "ename": "SignalException",
     "evalue": "Process 1765910 got signal: 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSignalException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DeepLearning/lib/python3.10/site-packages/ax/service/scheduler.py:949\u001b[0m, in \u001b[0;36mScheduler.run_all_trials\u001b[0;34m(self, timeout_hours, idle_callback)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mtotal_trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;66;03m# NOTE: Capping on number of trials will likely be needed as fallback\u001b[39;00m\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;66;03m# for most stopping criteria, so we ensure `num_trials` is specified.\u001b[39;00m\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    946\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease either specify `num_trials` in `SchedulerOptions` input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the `Scheduler` or use `run_n_trials` instead of `run_all_trials`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    948\u001b[0m     )\n\u001b[0;32m--> 949\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trials_and_yield_results(\n\u001b[1;32m    950\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39mnot_none(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mtotal_trials),\n\u001b[1;32m    951\u001b[0m     timeout_hours\u001b[38;5;241m=\u001b[39mtimeout_hours,\n\u001b[1;32m    952\u001b[0m     idle_callback\u001b[38;5;241m=\u001b[39midle_callback,\n\u001b[1;32m    953\u001b[0m ):\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummarize_final_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/DeepLearning/lib/python3.10/site-packages/ax/service/scheduler.py:830\u001b[0m, in \u001b[0;36mScheduler.run_trials_and_yield_results\u001b[0;34m(self, max_trials, ignore_global_stopping_strategy, timeout_hours, idle_callback)\u001b[0m\n\u001b[1;32m    825\u001b[0m         n_remaining_to_generate \u001b[38;5;241m=\u001b[39m n_remaining_to_run \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    826\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidate_trials\n\u001b[1;32m    827\u001b[0m         )\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;66;03m# Wait for trial evaluations to complete and process results.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completed_trials_and_report_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43midle_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midle_callback\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# When done scheduling, wait for the remaining trials to finish running\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# (unless optimization is aborting, in which case stop right away).\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_trials:\n",
      "File \u001b[0;32m~/anaconda3/envs/DeepLearning/lib/python3.10/site-packages/ax/service/scheduler.py:642\u001b[0m, in \u001b[0;36mScheduler.wait_for_completed_trials_and_report_results\u001b[0;34m(self, idle_callback)\u001b[0m\n\u001b[1;32m    632\u001b[0m log_seconds \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mint\u001b[39m(seconds_between_polls)\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m seconds_between_polls \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m seconds_between_polls\n\u001b[1;32m    636\u001b[0m )\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting for completed trials (for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_seconds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sec, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrently running trials: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_trials)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    640\u001b[0m )\n\u001b[0;32m--> 642\u001b[0m \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds_between_polls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m total_seconds_elapsed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m seconds_between_polls\n\u001b[1;32m    645\u001b[0m seconds_between_polls \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m backoff_factor\n",
      "File \u001b[0;32m~/anaconda3/envs/DeepLearning/lib/python3.10/site-packages/torchx/schedulers/local_scheduler.py:80\u001b[0m, in \u001b[0;36m_terminate_process_handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"Termination handler that raises exceptions on the main process.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mWhen the process receives death signal(SIGTERM, SIGINT), this termination handler will\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03mbe terminated.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m sigval \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mSignals(signum)\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m SignalException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcess \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mgetpid()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got signal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msigval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, sigval\u001b[38;5;241m=\u001b[39msigval)\n",
      "\u001b[0;31mSignalException\u001b[0m: Process 1765910 got signal: 2"
     ]
    }
   ],
   "source": [
    "scheduler.run_all_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925fa8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.utils.report_utils import exp_to_df\n",
    "\n",
    "df = exp_to_df(experiment)\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368eb147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.utils.report_utils import _pareto_frontier_scatter_2d_plotly\n",
    "\n",
    "_pareto_frontier_scatter_2d_plotly(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.modelbridge.cross_validation import compute_diagnostics, cross_validate\n",
    "from ax.plot.diagnostic import interact_cross_validation_plotly\n",
    "from ax.utils.notebook.plotting import init_notebook_plotting, render\n",
    "\n",
    "cv = cross_validate(model=scheduler.generation_strategy.model)  # The surrogate model is stored on the GenerationStrategy\n",
    "compute_diagnostics(cv)\n",
    "\n",
    "interact_cross_validation_plotly(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6783bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.plot.contour import interact_contour_plotly\n",
    "\n",
    "interact_contour_plotly(model=scheduler.generation_strategy.model, metric_name=\"compression_ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83dec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_contour_plotly(model=scheduler.generation_strategy.model, metric_name=\"psnr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
